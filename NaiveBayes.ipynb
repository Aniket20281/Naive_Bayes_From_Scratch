{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train , Y_train):\n",
    "    \n",
    "    # we will make a dictionary as decided for naive bayes(for storing count for probabilities)\n",
    "    answer = {}\n",
    "    \n",
    "    # classes will contain all possible classes in our Y_train\n",
    "    classes = set(Y_train)\n",
    "    for class_target in classes:\n",
    "        # class_target is the class for which we are storing the data first\n",
    "        \n",
    "        # we will need total number of data points to find .. \n",
    "        # ..probability so we will store it in our dictionary \n",
    "        answer[\"total_data\"] = len(Y_train)\n",
    "        \n",
    "        # Every class will have a dictionary associated with it\n",
    "        answer[class_target] = {}\n",
    "        \n",
    "        number_of_features = X_train.shape[1]\n",
    "        \n",
    "        # class_target_val will be a numpy of true/false corresponding to the ..\n",
    "        # .. data points in Y_train having the predicted class as class_target\n",
    "        class_target_val = (Y_train == class_target)\n",
    "        \n",
    "        # below two numpy arrays will fetch the rows for which we have true in ..\n",
    "        # .. class_target_val\n",
    "        X_train_val = X_train[class_target_val]\n",
    "        Y_train_val = Y_train[class_target_val]\n",
    "        \n",
    "        #we will store total count of the data points referring to target class ..\n",
    "        # .. for probability calculation\n",
    "        answer[class_target][\"total_count\"] = len(Y_train_val)\n",
    "        \n",
    "        # Now we will iterate in the features\n",
    "        for j in range(number_of_features):\n",
    "            answer[class_target][j] = {}\n",
    "            possible_values = set(X_train[:,j-1])\n",
    "            for curr in possible_values:\n",
    "                # the value below gives us the count of training data where the .. \n",
    "                # .. class is class_target and the value of Jth feature value is curr \n",
    "                answer[class_target][j][curr] = (X_train_val[:,j-1] == curr).sum()\n",
    "    return answer\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(x , class_target , data_dict):\n",
    "    class_probability = np.log(data_dict[class_target][\"total_count\"]) - np.log(data_dict[\"total_data\"])\n",
    "    feature_probability = 0\n",
    "    number_of_features = len(data_dict[class_target].keys()) - 1\n",
    "    for j in range(1,number_of_features):\n",
    "        xx = x[j-1]\n",
    "        count = data_dict[class_target][j][xx] + 1\n",
    "        different_values_feature_takes = len(data_dict[class_target][j].keys())\n",
    "        count_class = data_dict[class_target][\"total_count\"] + different_values_feature_takes\n",
    "        probab = np.log(count) - np.log(count_class)\n",
    "        feature_probability += probab \n",
    "    return class_probability + feature_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSingleDataPoint(x , data_dict):\n",
    "    classes = data_dict.keys()\n",
    "    flag = True\n",
    "    probability_predicted = -10000\n",
    "    class_predicted = -1\n",
    "    for class_target in classes:\n",
    "        if(class_target == \"total_data\"):\n",
    "            continue;\n",
    "        # we need to find some probabilities here\n",
    "        prob_current_class = prob(x , class_target , data_dict)\n",
    "        if(prob_current_class > probability_predicted or flag):\n",
    "            probability_predicted = prob_current_class\n",
    "            class_predicted = class_target\n",
    "        flag = False\n",
    "    return class_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test , data_dict):\n",
    "    Y_pred = []\n",
    "    for x in X_test:\n",
    "        # class_X will contain predicted value for data point x\n",
    "        class_x = predictSingleDataPoint(x , data_dict)\n",
    "        Y_pred.append(class_x)\n",
    "    return Y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataLabelled(column):\n",
    "    # We will\n",
    "    mid_limit = column.mean()\n",
    "    first_limit = mid_limit/2\n",
    "    second_limit = mid_limit*1.5\n",
    "    l = len(column)\n",
    "    for i in range(0,l):\n",
    "        if(column[i] < first_limit):\n",
    "            column[i] = 0\n",
    "        elif(column[i] < mid_limit):\n",
    "            column[i] = 1\n",
    "        elif(column[i] < second_limit):\n",
    "            column[i] = 2\n",
    "        else:\n",
    "            column[i] = 3\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       0.71      0.31      0.43        16\n",
      "           2       0.39      0.78      0.52         9\n",
      "\n",
      "    accuracy                           0.66        38\n",
      "   macro avg       0.70      0.70      0.65        38\n",
      "weighted avg       0.73      0.66      0.65        38\n",
      "\n",
      "[[13  0  0]\n",
      " [ 0  5 11]\n",
      " [ 0  2  7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "for i in range(0 , X.shape[-1]):\n",
    "    X[:,i] = makeDataLabelled(X[:,i])\n",
    "    \n",
    "X_train , X_test , Y_train , Y_test = model_selection.train_test_split(X , Y , test_size = 0.25 , random_state = 0)\n",
    "dic = fit(X_train , Y_train)\n",
    "Y_pred = predict(X_test , dic)\n",
    "from sklearn.metrics import classification_report , confusion_matrix\n",
    "print(classification_report(Y_test , Y_pred))\n",
    "print(confusion_matrix(Y_test , Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "gnb = MultinomialNB()\n",
    "gnb.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5263157894736842"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.score(X_test , Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
